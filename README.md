# Multi-Agent AI System - Educational Project

A comprehensive multi-agent system using **LangGraph** and **AutoGen** with support for local models (Ollama) and remote models (OpenAI).

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -e ".[dev]"

# 2. Configure environment variables
cp .env.example .env
# Edit .env with your API keys (optional for remote models)

# 3. Verify Ollama is running
ollama list

# 4. Run an example
python examples/01_simple_chat.py
```

## ğŸ“ Project Structure

```
multi_agent_system/
â”œâ”€â”€ src/multi_agent/
â”‚   â”œâ”€â”€ shared/              # Shared components
â”‚   â”‚   â”œâ”€â”€ config.py        # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ llm_factory.py   # Factory for local/remote LLMs
â”‚   â”‚   â””â”€â”€ memory.py        # Agent memory system
â”‚   â”œâ”€â”€ tools/               # Agent tools
â”‚   â”‚   â”œâ”€â”€ base.py          # Base tool interface
â”‚   â”‚   â””â”€â”€ common_tools.py  # Common tools (web, file, calc)
â”‚   â”œâ”€â”€ langgraph_agents/    # LangGraph implementation
â”‚   â”‚   â”œâ”€â”€ graph.py         # Multi-agent graph
â”‚   â”‚   â””â”€â”€ nodes.py         # Graph nodes (agents)
â”‚   â””â”€â”€ autogen_agents/      # AutoGen implementation
â”‚       â”œâ”€â”€ team.py          # Agent team
â”‚       â””â”€â”€ agents.py        # Agent definitions
â”œâ”€â”€ examples/                # Practical examples
â””â”€â”€ tests/                   # Automated tests
```

## ğŸ¤– Supported Models

### Local (Ollama)
- `mistral` - Balanced, great for general tasks
- `codellama` - Optimized for code generation
- `llama3.2` - Latest, good performance

### Remote
- OpenAI: `gpt-4o`, `gpt-4o-mini`
- Anthropic: `claude-3-sonnet`, `claude-3-haiku`
- Groq: `llama-3.1-70b-versatile`

## ğŸ“š Concepts Implemented

1. **LLM Abstraction**: Factory pattern for transparent local/remote switching
2. **Agent Memory**: Conversational + short-term memory for context
3. **Tool Calling**: Tool system with JSON schema
4. **Multi-Agent Orchestration**: Coordination between specialized agents
5. **State Management**: State management with LangGraph

## ğŸ“ Examples

| File | Description |
|------|-------------|
| `01_simple_chat.py` | Basic chat with local model |
| `02_tool_calling.py` | Agent with tool calling |
| `03_langgraph_team.py` | Multi-agent team with LangGraph |
| `04_autogen_team.py` | Multi-agent team with AutoGen |
| `05_memory_demo.py` | Agent with memory and basic RAG |

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_memory.py -v
```

## ğŸ“– Learning Path

1. Start with `01_simple_chat.py` to understand LLM abstraction
2. Explore `02_tool_calling.py` to learn about agent capabilities
3. Study `03_langgraph_team.py` for state-based multi-agent workflows
4. Compare with `04_autogen_team.py` for conversational multi-agent patterns
5. Dive into `05_memory_demo.py` for memory and RAG concepts

## ğŸ”§ Configuration

Edit `.env` file to configure:

```bash
# LLM Provider: "ollama" for local, "openai" for remote
LLM_PROVIDER=ollama
LLM_MODEL=mistral

# For remote providers
OPENAI_API_KEY=sk-your-key-here
```

## ğŸ“œ License

MIT License - Feel free to use for learning and projects!
