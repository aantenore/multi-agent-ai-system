# LLM Provider Configuration
# Choose: "gemini" (recommended), "ollama" for local, "openai" for remote
LLM_PROVIDER=gemini

# Model to use
# Gemini: gemini-3-pro-preview, gemini-2.0-flash, gemini-1.5-pro
# Ollama: mistral, codellama, llama3.2
# OpenAI: gpt-4o, gpt-4o-mini
LLM_MODEL=gemini-3-flash-preview

# Google API (recommended - primary provider)
GOOGLE_API_KEY=your-google-api-key-here

# OpenAI API (only if LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-your-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# Ollama (default localhost)
OLLAMA_HOST=http://localhost:11434

# Logging
LOG_LEVEL=INFO
